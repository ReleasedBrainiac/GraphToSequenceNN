{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test1: [[0. 1. 1. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]] \n",
      "\n",
      "\n",
      "Test2: [[0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Tensor(\"MyLambda/TensorArrayConcatV3:0\", dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "edges (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "features (InputLayer)           (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "MyLambda (Lambda)               (None, 9)            0           edges[0][0]                      \n",
      "                                                                 features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "LastDenseLayer (Dense)          (None, 9)            90          MyLambda[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 90\n",
      "Trainable params: 90\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [<tf.Variable 'Variable_3:0' shape=(4, 4) dtype=float32>, <tf.Variable 'Variable_1:0' shape=(4, 9) dtype=float32_ref>]...",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ec1e4b1626dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m           shuffle=False)\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;31m###########\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tobias.turke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    951\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tobias.turke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    785\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tobias.turke\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;34m'Expected to see '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' array(s), '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[1;34m'but instead got the following list of '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [<tf.Variable 'Variable_3:0' shape=(4, 4) dtype=float32>, <tf.Variable 'Variable_1:0' shape=(4, 9) dtype=float32_ref>]..."
     ]
    }
   ],
   "source": [
    "# - *- coding: utf- 8*-\n",
    "from LambdaNodeEmbedding import GetKerasNAP, KerasEval\n",
    "from NetworkHandler import GetKerasInputLayerPairs, GetMyKerasLambda, GetTestDense\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.callbacks import History\n",
    "\n",
    "#These are the edges between the nodes.\n",
    "edgelist = np.array([\n",
    "                    [0,1,1,1],\n",
    "                    [0,0,0,1],\n",
    "                    [0,1,0,0],\n",
    "                    [0,0,0,0]\n",
    "                    ], dtype='float32')\n",
    "\n",
    "#These are the node features examples\n",
    "features_init = np.array([\n",
    "                         [0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
    "                         [0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
    "                         [0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
    "                         [0., 1., 0., 0., 0., 0., 0., 1., 0.]\n",
    "                         ], dtype='float32')\n",
    "\n",
    "result_next_feat = np.array([\n",
    "                            [0., 0.6666667, 0., 0., 0.33333334, 0.33333334, 0.33333334, 0.33333334, 0.],\n",
    "                            [0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
    "                            [0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
    "                            [0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "                            ], dtype='float32')\n",
    "\n",
    "edgelist_ten = K.variable(value=edgelist, dtype='float32')\n",
    "fv_init_ten = K.variable(value=features_init, dtype='float32')\n",
    "result_feat_ten = K.variable(value=result_next_feat, dtype='float32')\n",
    "next_t, prev_t = GetKerasNAP(edgelist_ten)\n",
    "\n",
    "test_in = [next_t, fv_init_ten]\n",
    "\n",
    "print(\"Test1:\", KerasEval(test_in[0]), '\\n\\n')\n",
    "print(\"Test2:\", KerasEval(test_in[1]))\n",
    "\n",
    "\n",
    "###########\n",
    "#  Build  #\n",
    "###########\n",
    "\n",
    "ins = GetKerasInputLayerPairs((None,),\"edges\",(9,),\"features\")\n",
    "x = GetMyKerasLambda(ins,(9,),\"MyLambda\")\n",
    "x = GetTestDense(9, \"softmax\", \"LastDenseLayer\", x)\n",
    "model = Model(inputs=ins, outputs=x)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'], callbacks=[History])\n",
    "model.metrics_tensors += [layer.output for layer in model.layers] \n",
    "print(model.summary())\n",
    "\n",
    "###########\n",
    "#  Run 1  #\n",
    "###########\n",
    "\n",
    "model.fit(test_in, \n",
    "          test_in, \n",
    "          steps_per_epoch=1, \n",
    "          validation_steps=1, \n",
    "          epochs=1, \n",
    "          verbose=0, \n",
    "          shuffle=False)\n",
    "\n",
    "###########\n",
    "#  Run 2  #\n",
    "###########\n",
    "\n",
    "'''\n",
    "test_in = [next_t, fv_init_ten]\n",
    "t1 = [edgelist_ten, fv_init_ten]\n",
    "t2 = [edgelist, features_init]\n",
    "\n",
    "model.fit([edgelist_ten, fv_init_ten], \n",
    "          [t2], \n",
    "          steps_per_epoch=1, \n",
    "          validation_steps=1, \n",
    "          epochs=1, \n",
    "          verbose=0, \n",
    "          shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
